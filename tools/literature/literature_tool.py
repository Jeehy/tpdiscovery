import json
import sys
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from tools.literature.retriever import LiteratureRetriever
from prompts import LITERATURE_DISCOVERY_ANALYSIS, LITERATURE_VALIDATION_ANALYSIS
from deepseek_api import call_llm


class LiteratureTool:
    """
    æ–‡çŒ®éªŒè¯æ™ºèƒ½ä½“ (Literature Agent)
    èŒè´£ï¼š
    1. æ¥æ”¶åŸºå› éªŒè¯ä»»åŠ¡ (å¿…é¡»æ˜¾å¼æŒ‡å®š mode)
    2. è°ƒåº¦ Retriever è·å–åŸå§‹æ•°æ®
    3. æ„å»º Prompt å¹¶è°ƒç”¨ LLM è¿›è¡ŒéªŒè¯
    """
    
    def __init__(self):
        self.retriever = LiteratureRetriever()

    def verify_target(self, gene: str, disease: str, mode: str):
        """
        æ ¸å¿ƒéªŒè¯é€»è¾‘
        :param mode: "discovery" | "validation" (ç”±ä¸Šæ¸¸å¼ºåˆ¶æŒ‡å®šï¼Œä¸å†çŒœæµ‹)
        """
        # 1. ç›´æ¥è°ƒç”¨å·¥å…·è·å–æ•°æ®
        # å·¥å…·å±‚ä¼šæ ¹æ® mode è‡ªåŠ¨é€‰æ‹©æ˜¯æŸ¥æ³›ç™Œ(Discovery)è¿˜æ˜¯æŸ¥ç›´æ¥å…³è”(Validation)
        raw_docs = self.retriever.get_evidence(gene, disease, mode)
        
        if not raw_docs:
            return {
                "support_level": "No Evidence",
                "conclusion": f"No relevant literature found in {mode} mode.",
                "citations": []
            }

        # 2. æ•°æ®é¢„å¤„ç† (Context Preparation)
        top_docs = raw_docs[:5]
        context_str = "\n".join([
            f"[{i+1}] Title: {d['source_metadata'].get('title', 'Unknown')}\n"  
            f"    Aspect: {d.get('search_aspect', 'general')}\n"             
            f"    Content: {d['content'][:500]}..." 
            for i, d in enumerate(top_docs)
        ])

        # 3. æ„å»º Prompt (æ ¹æ® mode é€‰æ‹©å®Œå…¨ä¸åŒçš„é˜…è¯»ç­–ç•¥)
        sys_prompt = "ä½ æ˜¯èµ„æ·±ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®åˆ†æå¸ˆï¼Œè¯·ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼ã€‚"
        
        if mode == "discovery":
            # === Discovery Prompt: å¯»æ‰¾æ—è¯ ===
            user_prompt = LITERATURE_DISCOVERY_ANALYSIS.format(
                gene=gene, disease=disease, context_str=context_str
            )
        else:
            # === Validation Prompt: å¯»æ‰¾å®é”¤ ===
            user_prompt = LITERATURE_VALIDATION_ANALYSIS.format(
                gene=gene, disease=disease, context_str=context_str
            )

        print(f"  ğŸ§  [LitAgent] Analyzing {gene} ({mode})...")
        try:
            llm_res_str = call_llm(user_prompt, system_prompt=sys_prompt, json_mode=True)
            res_json = json.loads(llm_res_str)
            
            # =========== ğŸ› ï¸ å…³é”®ä¿®æ”¹ï¼šå›å¡«åŸå§‹è¯æ® ===========
            # å°† Top Docs çš„åŸå§‹æ–‡æœ¬å¡å›è¿”å›ç»“æœä¸­
            # è¿™æ ·ä¸»ç¨‹åºå°±èƒ½æ‹¿åˆ°åŸå§‹æ‘˜è¦äº†ï¼Œç´¢å¼•å·ä¸ LLM å¼•ç”¨å¯¹åº”
            res_json['raw_evidence_snippets'] = [
                {
                    "index": f"[{i+1}]",
                    "title": d['source_metadata'].get('title', 'Unknown'),       
                    "citation": d['source_metadata'].get('citation', 'Unknown'), 
                    "url": d['source_metadata'].get('url', ''),                  
                    "abstract": d['content'],
                    "source": d.get('source', 'Local_DB')
                }
                for i, d in enumerate(top_docs)
            ]
            # ===============================================
            
            return res_json
        except Exception as e:
            print(f"  âš ï¸ LLM Error: {e}")
            return {"error": "LLM Analysis Failed"}

    def run_batch_verification(self, gene_list: list, disease: str, mode: str, max_workers: int = 2, max_genes: int = 20, request_delay: float = 1.0):
        """
        æ‰¹é‡è¿è¡Œå…¥å£
        :param mode: å¿…é¡»æ˜¾å¼ä¼ å…¥ "discovery" æˆ– "validation"
        :param max_workers: å¹¶è¡Œçº¿ç¨‹æ•° (é»˜è®¤2ï¼Œé¿å… PubMed API é™æµ)
        :param max_genes: æœ€å¤šéªŒè¯çš„åŸºå› æ•°é‡ (é»˜è®¤20)
        :param request_delay: æ¯æ¬¡è¯·æ±‚é—´éš”ç§’æ•° (é»˜è®¤1.0ç§’ï¼ŒPubMed é™åˆ¶çº¦3æ¬¡/ç§’)
        """
        
        if len(gene_list) > max_genes:
            print(f"âš ï¸ [LitAgent] å€™é€‰æ± è¿‡å¤§ ({len(gene_list)})ï¼ŒåªéªŒè¯å‰ {max_genes} ä¸ª")
            gene_list = gene_list[:max_genes]
        print(f"\nğŸ“– [LitAgent] å¹¶è¡Œå¤„ç† {len(gene_list)} ä¸ªåŸºå›  ({max_workers} workers) [{mode.upper()}] mode...")
        results = {}
        
        # é¢„å¤„ç†åŸºå› å
        genes_to_verify = [
            item['Gene'] if isinstance(item, dict) else item 
            for item in gene_list
        ]
        
        def verify_single(gene):
            return gene, self.verify_target(gene, disease, mode)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            for i, g in enumerate(genes_to_verify):
                futures[executor.submit(verify_single, g)] = g
                # æœ¬åœ°æ£€ç´¢å‡ ä¹ä¸éœ€è¦ delayï¼Œç»™ä¸€ç‚¹ç‚¹åªæ˜¯ä¸ºäº†æ—¥å¿—ä¸åˆ·å±
                if i < len(genes_to_verify) - 1:
                    time.sleep(request_delay)
            
            for future in as_completed(futures):
                try:
                    gene, res = future.result()
                    results[gene] = res
                except Exception as e:
                    gene = futures[future]
                    print(f"  âš ï¸ {gene} éªŒè¯å¤±è´¥: {e}")
                    results[gene] = {"error": str(e)}
        
        print(f"âœ… [LitAgent] å®Œæˆ {len(results)} ä¸ªåŸºå› éªŒè¯")
        return results