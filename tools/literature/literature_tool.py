import json
from tools.literature.literature_retriever import LiteratureRetriever
import requests, time, os
from dotenv import load_dotenv

# === é…ç½® DeepSeek ===
BASE_URL = "https://api.deepseek.com/chat/completions"
load_dotenv()
API_KEY = os.getenv("DEEPSEEK_API_KEY")

def call_deepseek(user_prompt: str, system_prompt: str = "You are a helpful assistant.", json_mode: bool = False, timeout: int = 60, retries: int = 3) -> str:
    """
    é€šç”¨ DeepSeek è°ƒç”¨å‡½æ•°
    :param user_prompt: ç”¨æˆ·è¾“å…¥
    :param system_prompt: ç³»ç»Ÿè®¾å®š (è§’è‰²/ä»»åŠ¡çº¦æŸ)
    :param json_mode: æ˜¯å¦å¼ºåˆ¶è¾“å‡º JSON æ ¼å¼
    :param timeout: è¶…æ—¶æ—¶é—´
    :param retries: é‡è¯•æ¬¡æ•°
    :return: æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹ (å¦‚æœæ˜¯ JSON æ¨¡å¼ï¼Œé€šå¸¸éœ€è¦ json.loads è§£æ)
    """
    headers = {
        "Content-Type": "application/json", 
        "Authorization": f"Bearer {API_KEY}"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "stream": False,
        "temperature": 0.3 # ä¿æŒä½æ¸©åº¦ä»¥è·å¾—ç¨³å®šç»“æœ
    }
    
    # å…³é”®ä¿®æ”¹ï¼šæ”¯æŒ JSON Mode
    if json_mode:
        payload["response_format"] = {"type": "json_object"}

    for attempt in range(retries):
        try:
            response = requests.post(BASE_URL, headers=headers, json=payload, timeout=timeout)
            
            if response.status_code != 200:
                print(f"âš ï¸ [API Error] {response.status_code}: {response.text}")
                if response.status_code >= 500: # æœåŠ¡ç«¯é”™è¯¯å¯ä»¥é‡è¯•
                    time.sleep(2)
                    continue
                else:
                    return "" # å®¢æˆ·ç«¯é”™è¯¯(4xx)ç›´æ¥è¿”å›ç©º

            result = response.json()
            content = result["choices"][0]["message"]["content"]
            return content

        except Exception as e:
            print(f"âš ï¸ [Network Error] Attempt {attempt+1}/{retries}: {e}")
            time.sleep(2)
            
    return ""

class LiteratureTool:
    """
    æ–‡çŒ®éªŒè¯æ™ºèƒ½ä½“ (Literature Agent)
    èŒè´£ï¼š
    1. æ¥æ”¶åŸºå› éªŒè¯ä»»åŠ¡ (å¿…é¡»æ˜¾å¼æŒ‡å®š mode)
    2. è°ƒåº¦ Retriever è·å–åŸå§‹æ•°æ®
    3. æ„å»º Prompt å¹¶è°ƒç”¨ LLM è¿›è¡ŒéªŒè¯
    """
    
    def __init__(self):
        self.retriever = LiteratureRetriever()

    def verify_target(self, gene: str, disease: str, mode: str):
        """
        æ ¸å¿ƒéªŒè¯é€»è¾‘
        :param mode: "discovery" | "validation" (ç”±ä¸Šæ¸¸å¼ºåˆ¶æŒ‡å®šï¼Œä¸å†çŒœæµ‹)
        """
        # 1. ç›´æ¥è°ƒç”¨å·¥å…·è·å–æ•°æ®
        # å·¥å…·å±‚ä¼šæ ¹æ® mode è‡ªåŠ¨é€‰æ‹©æ˜¯æŸ¥æ³›ç™Œ(Discovery)è¿˜æ˜¯æŸ¥ç›´æ¥å…³è”(Validation)
        raw_docs = self.retriever.get_evidence(gene, disease, mode)
        
        if not raw_docs:
            return {
                "support_level": "No Evidence",
                "conclusion": f"No relevant literature found in {mode} mode.",
                "citations": []
            }

        # 2. æ•°æ®é¢„å¤„ç† (Context Preparation)
        top_docs = raw_docs[:5]
        context_str = "\n".join([
            f"[{i+1}] Title: {d['metadata']['title']}\n"
            f"    Aspect: {d.get('aspect', 'general')}\n"
            f"    Content: {d['content'][:500]}..." 
            for i, d in enumerate(top_docs)
        ])

        # 3. æ„å»º Prompt (æ ¹æ® mode é€‰æ‹©å®Œå…¨ä¸åŒçš„é˜…è¯»ç­–ç•¥)
        sys_prompt = "You are a Senior Bio-curator. Output strictly in JSON."
        
        if mode == "discovery":
            # === Discovery Prompt: å¯»æ‰¾æ—è¯ ===
            user_prompt = f"""
            Target Gene: {gene}
            Context: Potential NOVEL target for {disease}.
            Search Mode: Discovery (Looking for indirect evidence in other cancers/mechanisms).
            
            Literature Evidence:
            {context_str}
            
            Task:
            1. **Translatability**: Is this gene a driver or drug target in OTHER cancers (e.g., Lung, Breast)?
            2. **Mechanism**: Does it regulate a core pathway (e.g., Apoptosis, EMT) that is relevant to {disease}?
            
            Return JSON:
            {{
                "lit_support_level": "Indirect-High (Proven in other cancers)" or "Low",
                "lit_conclusion": "Briefly summarize its potential for repurposing in {disease} based on side evidence.",
                "key_citations": ["Author, Year", ...]
            }}
            """
        else:
            # === Validation Prompt: å¯»æ‰¾å®é”¤ ===
            user_prompt = f"""
            Target Gene: {gene}
            Context: Candidate target for {disease}.
            Search Mode: Validation (Looking for DIRECT evidence in {disease}).
            
            Literature Evidence:
            {context_str}
            
            Task:
            1. **Direct Evidence**: Is there direct mention of {gene} in {disease}?
            2. **Clinical Link**: Is it linked to prognosis, survival, or drug resistance in {disease}?
            
            Return JSON:
            {{
                "lit_support_level": "Strong (Direct Link)" or "Weak",
                "lit_conclusion": "Briefly summarize the direct evidence in {disease}.",
                "key_citations": ["Author, Year", ...]
            }}
            """

        print(f"  ğŸ§  [LitAgent] Analyzing {gene} ({mode})...")
        try:
            llm_res_str = call_deepseek(user_prompt, sys_prompt, json_mode=True)
            res_json = json.loads(llm_res_str)
            
            # =========== ğŸ› ï¸ å…³é”®ä¿®æ”¹ï¼šå›å¡«åŸå§‹è¯æ® ===========
            # å°† Top Docs çš„åŸå§‹æ–‡æœ¬å¡å›è¿”å›ç»“æœä¸­
            # è¿™æ ·ä¸»ç¨‹åºå°±èƒ½æ‹¿åˆ°åŸå§‹æ‘˜è¦äº†
            res_json['raw_evidence_snippets'] = [
                {
                    "title": d['metadata']['title'],
                    "citation": d['metadata'].get('citation', 'Unknown'),
                    "abstract": d['content'], # ä¿ç•™å®Œæ•´æ‘˜è¦
                    "source": d.get('source', 'Online')
                }
                for d in top_docs
            ]
            # ===============================================
            
            return res_json
        except Exception as e:
            print(f"  âš ï¸ LLM Error: {e}")
            return {"error": "LLM Analysis Failed"}

    def run_batch_verification(self, gene_list: list, disease: str, mode: str):
        """
        æ‰¹é‡è¿è¡Œå…¥å£
        :param mode: å¿…é¡»æ˜¾å¼ä¼ å…¥ "discovery" æˆ– "validation"
        """
        print(f"\nğŸ“– [LitAgent] Batch processing {len(gene_list)} genes in [{mode.upper()}] mode...")
        results = {}
        
        for item in gene_list:
            # å…¼å®¹ item æ˜¯å­—å…¸æˆ–å­—ç¬¦ä¸²çš„æƒ…å†µ
            gene = item['Gene'] if isinstance(item, dict) else item
            
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å…¨å±€ modeï¼Œä¸å†çœ‹ Tier
            res = self.verify_target(gene, disease, mode)
            results[gene] = res
            
        return results